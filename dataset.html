<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="css/dataset.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
	<title>Yulan Guo's Homepage</title>
</head>

<body bgcolor="#ffffff">
<div id="site-content">
  	<div class="container Mobile">
	  	<h4>Datasets</h4>
		<h6>This is an incomplete list of point cloud/mesh/RGBD datasets, please email <strong><font color="red">Yulan Guo</font></strong> to add or update the list</h6>
	  		
			
	  	<h5>3D Model/Shape Retrieval Datasets</h5>
		<div class="paper">
			<div class="ptitle">ShapeNet Dataset</div>
			<div class="pdiscrible"> The ShapeNetCore covers 55 common object categories with about 51,300 unique 3D models. The ShapeNetSem is a smaller, more densely annotated subset consisting of 12,000 models spread over a broader set of 270 categories.</div>
		   <div class="plink"><a href="https://www.shapenet.org/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">ModelNet Dataset</div>
			<div class="pdiscrible">It contains 127915 3D CAD models from 662 categories</div>
		   <div class="plink"><a href="http://modelnet.cs.princeton.edu/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">UWA Dataset</div>
			<div class="pdiscrible">@ University of Western Australia, Australia</div>
		   <div class="plink"><a href="http://www.csse.uwa.edu.au/%7Eajmal/databases.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Princeton Shape Benchmark</div>
			<div class="pdiscrible">(PSB) @Princeton University, US</div>
		   <div class="plink"><a href="http://shape.cs.princeton.edu/benchmark/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Colored 3D Model Database</div>
			<div class="pdiscrible">(CDB) @ JiLin University, China</div>
		   <div class="plink"><a href="http://59.72.0.46/cg/old/cdb.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">SHREC10 Datasets</div>
			<div class="pdiscrible">it includes three benchmarks: robust large-scale retrieval, correspondence, and feature detection and description</div>
		   <div class="plink"><a href="http://tosca.cs.technion.ac.il/book/resources_data.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">TOSCA High-Resolution</div>
			<div class="pdiscrible">it contains a total of 80 objects, including 11 cats, 9 dogs, 3 wolves, 8 horses, 6 centaurs, 4 gorillas, 12 female figures, and two different male figures, containing 7 and 20 poses</div>
		   <div class="plink"><a href="http://tosca.cs.technion.ac.il/book/resources_data.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Non-Rigid World</div>
			<div class="pdiscrible">it contains a total of 148 objects, including 9 cats, 11 dogs, 3 wolves, 17 horses, 15 lions, 21 gorillas, 1 shark, 24 female figures, and two different male figures, containing 15 and 20 poses</div>
		   <div class="plink"><a href="http://tosca.cs.technion.ac.il/book/resources_data.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">NTU 3D Model Benchmark ver.1</div>
			<div class="pdiscrible">it contains 1833 3D models</div>
		   <div class="plink"><a href="http://3d.csie.ntu.edu.tw/~dynamic/benchmark/index.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">NTU 3D Model Database ver.1</div>
			<div class="pdiscrible">it contains 10911 3D models</div>
		   <div class="plink"><a href="http://3d.csie.ntu.edu.tw/~dynamic/database/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Make3D Range Image Data</div>
			<div class="pdiscrible">This dataset contains aligned image and range data. 1) Make3D Image and Laser Depthmap. 2) Image and Laser and Stereo. 3) Image and 1D Laser. 4) Image and Depth for Objects</div>
		   <div class="plink"><a href="http://make3d.cs.cornell.edu/data.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Large Geometric Models Archive</div>
			<div class="pdiscrible">@ Georgia Institute of Technology</div>
		   <div class="plink"><a href="http://www.cc.gatech.edu/projects/large_models/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">The CAnonically Posed 3D Objects Dataset</div>
			<div class="pdiscrible">It contains a total of 180 generic objects uniformly distributed into 15 classes</div>
		   <div class="plink"><a href="https://sites.google.com/site/pgpapadakis/home/CAPOD" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">MIT CSAIL Textured Models Database</div>
			<div class="pdiscrible">It provides several textured 3D models from the MIT CSAIL database</div>
		   <div class="plink"><a href="http://people.csail.mit.edu/tmertens/textransfer/data/" target="_blank" rel="nofollow">download</a></div>
		</div>
		
		
		<h5>3D Object Detection/Recognition Datasets </h5>
		<div class="paper">
			<div class="ptitle">Sydney Urban Objects Dataset</div>
			<div class="pdiscrible">It contains labeled Velodyne LiDAR scans of 631 urban objects in 26 categories</div>
		   <div class="plink"><a href="http://www.acfr.usyd.edu.au/papers/SydneyUrbanObjectsDataset.shtml" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">UWA Dataset</div>
			<div class="pdiscrible">@ University of Western Australia, Australia</div>
		   <div class="plink"><a href="http://staffhome.ecm.uwa.edu.au/~00053650/databases.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Queen's Range Image and 3-D Model Database</div>
			<div class="pdiscrible">@ Queen's University, Canada</div>
		   <div class="plink"><a href="http://rcvlab.ece.queensu.ca/%7Eqridb/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Ca' Foscari Venezia Dataset</div>
			<div class="pdiscrible">It is designed for 3D object recognition and segmentation in clutter, developed by the Universit√† Ca' Foscari Venezia, Italy</div>
		   <div class="plink"><a href="http://www.dsi.unive.it/%7Erodola/data.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">USF Database</div>
			<div class="pdiscrible">@ University of South Florida, US</div>
		   <div class="plink"><a href="http://marathon.csee.usf.edu/range/seg-comp/SegComp.html" target="_blank" rel="nofollow">download</a></div>
		</div>	
		<div class="paper">
			<div class="ptitle">RGB-D Object Dataset</div>
			<div class="pdiscrible">@ University of Washington, US</div>
		   <div class="plink"><a href="http://rgbd-dataset.cs.washington.edu/index.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">YCB Object and Model Set</div>
			<div class="pdiscrible">@ Yale-CMU-Berkeley  Universities, US</div>
		   <div class="plink"><a href="http://ycbbenchmarks.org/" target="_blank" rel="nofollow">download</a></div>
		</div>
		
		<h5>RGB-D Object Datasets</h5>
		<div class="paper">
			<div class="ptitle">RGB-D Dataset 7-Scenes</div>
			<div class="pdiscrible">A collection of tracked RGB-D camera frames. The dataset may be used for evaluation of methods for different applications such as dense tracking and mapping and relocalization techniques</div>
		   <div class="plink"><a href="https://www.microsoft.com/en-us/research/project/rgb-d-dataset-7-scenes/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2F7-scenes%2F" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Cornell-RGBD-Dataset</div>
			<div class="pdiscrible">This data set has 24 labeled office scene point clouds and 28 labeled home scene point clouds</div>
		   <div class="plink"><a href="http://pr.cs.cornell.edu/sceneunderstanding/data/data.php" target="_blank" rel="nofollow">download</a></div>
		</div>		
		<div class="paper">
			<div class="ptitle">RGB-D Object Dataset</div>
			<div class="pdiscrible">A large dataset of 300 common household objects. The objects are organized into 51 categories arranged using WordNet hypernym-hyponym relationships (similar to ImageNet). This dataset was recorded using a Kinect style 3D camera</div>
		   <div class="plink"><a href="http://rgbd-dataset.cs.washington.edu/" target="_blank" rel="nofollow">download</a></div>
		</div>		
		<div class="paper">
			<div class="ptitle">NYU Depth Dataset V2</div>
			<div class="pdiscrible">The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect</div>
		   <div class="plink"><a href="http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" target="_blank" rel="nofollow">download</a></div>
		</div>		
		<div class="paper">
			<div class="ptitle">YCB Object and Model Set</div>
			<div class="pdiscrible">CAD-60 & CAD-120: The CAD-60 and CAD-120 data sets comprise of RGB-D video sequences of humans performing activities which are recording using the Microsoft Kinect sensor</div>
		   <div class="plink"><a href="http://ycbbenchmarks.org/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">A list of RGBD Datasets</div>
			<div class="pdiscrible">This is an incomplete list of datasets which were captured using a Kinect or similar devices</div>
		   <div class="plink"><a href="www0.cs.ucl.ac.uk/staff/M.Firman/RGBDdatasets/" target="_blank" rel="nofollow">download</a></div>
		</div>
		
		<h5>3D Keypoint Detection and Feature Description Datasets</h5>
		<div class="paper">
			<div class="ptitle">3D Keypoint Detection Dataset</div>
			<div class="pdiscrible">It contains 5 parts for evaluating the performance of 3D keypoint detectors. The whole dataset comes with groundtruth</div>
		   <div class="plink"><a href="http://vision.deis.unibo.it/fede/datasets" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Benchmark for 3D Interest Point Detection</div>
			<div class="pdiscrible">This benchmark aims to provide tools to evaluate 3D Interest Point Detection Algorithms with respect to human generated ground truth.</div>
		   <div class="plink"><a href="http://www.itl.nist.gov/iad/vug/sharp/benchmark/3DInterestPoint/" target="_blank" rel="nofollow">download</a></div>
		</div>
		
		
		<h5>3D Face Recognition/Analysis Datasets</h5>
		<div class="paper">
			<div class="ptitle">FRGC</div>
			<div class="pdiscrible">Face Recognition Grand Challenge</div>
		   <div class="plink"><a href="http://www.nist.gov/itl/iad/ig/frgc.cfm" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">BU-3DFE</div>
			<div class="pdiscrible">Binghamton University 3D Facial Expression</div>
		   <div class="plink"><a href="http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">BU-4DFE (3D + time)</div>
			<div class="pdiscrible">A 3D Dynamic Facial Expression Database</div>
		   <div class="plink"><a href="http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Human Face</div>
			<div class="pdiscrible">An animated three-dimensional face showing different facial expressions, acquired using a real-time range camera</div>
		   <div class="plink"><a href="http://tosca.cs.technion.ac.il/book/resources_data.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">NTU-CSP 3D Face Database</div>
			<div class="pdiscrible">It is a multimodal database of 3D human faces composed by 3D scans of 80 different persons</div>
		   <div class="plink"><a href="http://eeeweba.ntu.edu.sg/csp-3dfdb/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Bosphorus 3D and 2D Database</div>
			<div class="pdiscrible">It is a multimodal database of 3D human faces composed by 3D scans of 80 different persons</div>
		   <div class="plink"><a href="http://bosphorus.ee.boun.edu.tr/default.aspx" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">University of Houston Database</div>
			<div class="pdiscrible"></div>
		   <div class="plink"><a href="https://sites.google.com/a/nd.edu/public-cvrl/data-sets" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Spacetime Faces</div>
			<div class="pdiscrible">High-Resolution Capture for Modeling and Animation</div>
		   <div class="plink"><a href="http://grail.cs.washington.edu/projects/stfaces/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">ETH Face Pose Range Image Data Set</div>
			<div class="pdiscrible">Range images of faces with ground truth used in CVPR08 paper "Real-Time Face Pose Estimation from Single Range Images</div>
		   <div class="plink"><a href="http://www.vision.ee.ethz.ch/datasets/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">Biwi Kinect Head Pose Database</div>
			<div class="pdiscrible">Over 15K images of 20 people recorded with a Kinect while turning their heads around freely</div>
		   <div class="plink"><a href="http://www.vision.ee.ethz.ch/datasets/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">BIWI 3D Audiovisual Corpus of Affective Communication</div>
			<div class="pdiscrible">It contains high quality dynamic (25 fps) 3D scans of faces recorded while pronouncing a set of English sentences</div>
		   <div class="plink"><a href="http://www.vision.ee.ethz.ch/datasets/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">University of York 3D Face Database</div>
			<div class="pdiscrible">Ten facial surfaces of 97 different people were captured, under the conditions</div>
		   <div class="plink"><a href="http://www-users.cs.york.ac.uk/~nep/research/3Dface/tomh/3DFaceDatabase.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">3D_RMA</div>
			<div class="pdiscrible">120 persons were asked to pose twice in front of the system</div>
		   <div class="plink"><a href="http://www.sic.rma.ac.be/~beumier/DB/3d_rma.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">BP4D-Spontanous</div>
			<div class="pdiscrible">Binghamton-Pittsburgh 3D Dynamic Spontaneous Facial Expression Database</div>
		   <div class="plink"><a href="http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">FaceWarehouse</div>
			<div class="pdiscrible">A RGBD Facial Expression Database for Visual Computing</div>
		   <div class="plink"><a href="http://gaps-zju.org/facewarehouse/" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">EURECOM Kinect Face Dataset</div>
			<div class="pdiscrible">A database of images of different facial expressions in different lighting and occlusion conditions to serve various research purposes. The Dataset consists of the multimodal facial images of 52 people (14 females, 38 males) obtained by Kinect</div>
		   <div class="plink"><a href="http://rgb-d.eurecom.fr/" target="_blank" rel="nofollow">download</a></div>
		</div>
		
		
		<h5>Other 3D Point Clouds Datasets</h5>
		<div class="paper">
			<div class="ptitle">Canadian Planetary Emulation Terrain 3D Mapping Dataset</div>
			<div class="pdiscrible">A collection of three-dimensional laser scans gathered at two unique planetary analogue rover test facilities in Canada</div>
		   <div class="plink"><a href="http://asrl.utias.utoronto.ca/datasets/3dmap/#References" target="_blank" rel="nofollow">download</a></div>
		</div>
		<div class="paper">
			<div class="ptitle">ASL Datasets Repository</div>
			<div class="pdiscrible">Laser and Kinect data from structured and unstructured environments</div>
		   <div class="plink"><a href="http://projects.asl.ethz.ch/datasets/doku.php" target="_blank" rel="nofollow">download</a></div>
		</div>	
		<div class="paper">
			<div class="ptitle">3D Urban Scenes</div>
			<div class="pdiscrible">It concerns urban scenes, was acquired with a lidar sensor</div>
		   <div class="plink"><a href="http://vision.deis.unibo.it/fede/3Dsegm.html" target="_blank" rel="nofollow">download</a></div>
		</div>			
		<div class="paper">
			<div class="ptitle">PCL 3D Point Clouds</div>
			<div class="pdiscrible">More point cloud datasets can be found in PCL</div>
		   <div class="plink"><a href="http://pointclouds.org/media/" target="_blank" rel="nofollow">download</a></div>
		</div>		
	</div>	
</body>
</html>
